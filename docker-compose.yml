version: '3'
services:
  web:
    build: .
    restart: "always"
    ports:
      - '8080:8080'
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${SQL_ALCHEMY_CONN}
      - AIRFLOW__WEBSERVER__DAG_ORIENTATION=${DAG_ORIENTATION}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${SECRET_KEY}
    volumes:
      - '${PWD}/dockerdata/logs:/logs'
    links:
      - db
    entrypoint:
      - /airflow/airflow_web.sh

  scheduler:
    build: .
    restart: "always"
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${SQL_ALCHEMY_CONN}
    volumes:
      - '${PWD}/dockerdata/logs:/logs'
    links:
      - db
      - redis
      - worker
    entrypoint:
      - /airflow/airflow_scheduler.sh

  worker:
    build: .
    restart: "always"
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${SQL_ALCHEMY_CONN}
      - C_FORCE_ROOT=True
    volumes:
      - '${PWD}/dockerdata/logs:/logs'
    links:
      - db
      - redis
    entrypoint:
      - /airflow/airflow_worker.sh

  flower:
    build: .
    restart: "always"
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${SQL_ALCHEMY_CONN}
    volumes:
      - '${PWD}/dockerdata/logs:/logs'
    ports:
      - '8081:8081'
    links:
      - db
      - redis
    entrypoint:
      - /airflow/airflow_flower.sh

  db:
    image: 'postgres:9.6'
    hostname: db
    restart: always
    volumes:
      - '${PWD}/dockerdata/pgdata:/var/lib/postgresql/data'
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow

  redis:
    image: 'redis:3.2'
    hostname: redis
    restart: "always"
    volumes:
      - '${PWD}/dockerdata/redis:/data'
